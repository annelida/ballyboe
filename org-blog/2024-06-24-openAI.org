#+BEGIN_EXPORT html
---
layout: page
title: OpenAI
tagline: " how start to think like a professional ChatGPT prompt engineer"
permalink: /openAI/open-ai.html
categories: [openAI]
tags: [openAI]
---
#+END_EXPORT
#+STARTUP: showall indent
#+OPTIONS: tags:nil num:nil \n:nil @:t ::t |:t ^:{} _:{} *:t
#+PROPERTY: header-args :exports both
#+PROPERTY: header-args+ :results output pp
#+PROPERTY: header-args+ :eval no-export
#+TOC: headlines 2

* Preamble

* Set up a virtual environment

** Creation

#+begin_src sh
 virtualenv ~/.local/venvs/ViOAI
 ls ~/.local/venvs
#+end_src

#+RESULTS:
: created virtual environment CPython3.11.2.final.0-64 in 207ms
:   creator CPython3Posix(dest=/home/vikky/.local/venvs/ViOAI, clear=False, no_vcs_ignore=False, global=False)
:   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/vikky/.local/share/virtualenv)
:     added seed packages: pip==23.0.1, setuptools==66.1.1, wheel==0.38.4
:   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
: ViEnv0.1
: ViEnv0.2
: ViOAI
: VirtSel

** Activate =venv= inside Emacs:

#+begin_src elisp
(pyvenv-activate "~/.local/venvs/ViEnv0.1")
#+end_src

** Check-up a list of installed packaages:

#+begin_src sh
pip list
#+end_src

#+RESULTS:
: Package    Version
: ---------- -------
: pip        23.0.1
: setuptools 66.1.1
: wheel      0.38.4

* Install the OpenAI Python library

#+begin_src sh
pip install --upgrade openai
#+end_src

#+RESULTS:
#+begin_example
Collecting openai
  Using cached openai-1.35.3-py3-none-any.whl (327 kB)
Collecting anyio<5,>=3.5.0
  Using cached anyio-4.4.0-py3-none-any.whl (86 kB)
Collecting distro<2,>=1.7.0
  Using cached distro-1.9.0-py3-none-any.whl (20 kB)
Collecting httpx<1,>=0.23.0
  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)
Collecting pydantic<3,>=1.9.0
  Using cached pydantic-2.7.4-py3-none-any.whl (409 kB)
Collecting sniffio
  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Collecting tqdm>4
  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)
Collecting typing-extensions<5,>=4.7
  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Collecting idna>=2.8
  Using cached idna-3.7-py3-none-any.whl (66 kB)
Collecting certifi
  Using cached certifi-2024.6.2-py3-none-any.whl (164 kB)
Collecting httpcore==1.*
  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)
Collecting h11<0.15,>=0.13
  Using cached h11-0.14.0-py3-none-any.whl (58 kB)
Collecting annotated-types>=0.4.0
  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Collecting pydantic-core==2.18.4
  Using cached pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
Installing collected packages: typing-extensions, tqdm, sniffio, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, openai
Successfully installed annotated-types-0.7.0 anyio-4.4.0 certifi-2024.6.2 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 openai-1.35.3 pydantic-2.7.4 pydantic-core-2.18.4 sniffio-1.3.1 tqdm-4.66.4 typing-extensions-4.12.2
#+end_example

** Check up again a list of installed packages

#+begin_src sh
pip list
#+end_src

#+RESULTS:
#+begin_example
Package           Version
----------------- --------
annotated-types   0.7.0
anyio             4.4.0
certifi           2024.6.2
distro            1.9.0
h11               0.14.0
httpcore          1.0.5
httpx             0.27.0
idna              3.7
openai            1.35.3
pip               23.0.1
pydantic          2.7.4
pydantic_core     2.18.4
setuptools        66.1.1
sniffio           1.3.1
tqdm              4.66.4
typing_extensions 4.12.2
wheel             0.38.4
#+end_example

* Making an API request

#+begin_src python
  import textwrap
  from openai import OpenAI
  client = OpenAI()

  completion = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a professional ChatGPT prompt engineer with deep and profound knowledge of OpenAI subtleties and Python."},
        {"role": "user", "content": "What is Python list?"}
    ]
    )

  width = 70

  for meSsage in completion.choices:
       print(textwrap.fill(meSsage.message.content, width))

#+end_src

#+RESULTS:
: In Python, a list is a built-in data structure used to store a
: collection of items. It is a mutable, ordered sequence of elements
: that can contain elements of different data types. Lists are declared
: by enclosing the elements in square brackets `[]` and separating them
: with commas.  For example:  ```python my_list = [1, 2, 3, 4, 5] ```
: Lists allow for various operations like indexing, slicing, appending,
: removing, and more. They are quite versatile and commonly used in
: Python for storing and manipulating collections of data.

* Input parameters

** Required

- model: the name of the model you want to use (e.g., gpt-3.5-turbo,
  gpt-4, gpt-3.5-turbo-16k-1106);
- messages: a list of message objects, where each object has two
  required fields:

  - role: the role of the messenger (either system, user, assistant or
 tool);
  - content: the content of the message..

** Optional

- frequency_penalty: Penalizes tokens based on their frequency,
  reducing repetition;
- logit_bias: Modifies likelihood of specified tokens with bias
  values;
- logprobs: Returns log probabilities of output tokens if true;
- top_logprobs: Specifies the number of most likely tokens to return
  at each position;
- max_tokens: Sets the maximum number of generated tokens in chat
  completion;
- n: Generates a specified number of chat completion choices for each
 input;
- presence_penalty: Penalizes new tokens based on their presence in
  the text;
- response_format: Specifies the output format, e.g., JSON mode;
- seed: Ensures deterministic sampling with a specified seed;
- stop: Specifies up to 4 sequences where the API should stop
  generating tokens;
- stream: Sends partial message deltas as tokens become available;
- temperature: Sets the sampling temperature between 0 and 2;
- top_p: Uses nucleus sampling; considers tokens with top_p
  probability mass;
- tools: Lists functions the model may call;
- tool_choice: Controls the model's function calls
  (none/auto/function);
- user: Unique identifier for end-user monitoring and abuse detection.
